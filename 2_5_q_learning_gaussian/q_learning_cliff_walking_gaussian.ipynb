{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning\n",
    "\n",
    "### <font color='orange'>Universidad Autónoma de Yucatán</font> _Facultad de Matemáticas_\n",
    "\n",
    "**Teacher:** Dr. Victor Uc Cetina <[victoruccetina@gmail.com](mailto:victoruccetina@gmail.com)>\n",
    "\n",
    "**Student:** Ing. Dayan Bravo Fraga <[dayan3847@gmail.com](mailto:dayan3847@gmail.com)>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47442e0fa8e38969"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cliff Walking\n",
    "\n",
    "<img src=\"../2_4_q_learning_tables/img/cliff_walking.png\" width=\"500\"></img>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c784dc1f3d31000"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:14:20.485837608Z",
     "start_time": "2023-12-03T20:14:20.223900040Z"
    }
   },
   "id": "3779072dd33419c7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:14:20.492360961Z",
     "start_time": "2023-12-03T20:14:20.486797051Z"
    }
   },
   "outputs": [],
   "source": [
    "from dayan3847.reinforcement_learning.cliff_walking.agent import Environment, AgentQLearning, AgentQLearningGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:14:20.600391568Z",
     "start_time": "2023-12-03T20:14:20.492493401Z"
    }
   },
   "id": "c0fa6e3c7fa39ccc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "environment: Environment = Environment()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:14:20.621337260Z",
     "start_time": "2023-12-03T20:14:20.606372465Z"
    }
   },
   "id": "5b4f922832e1d35c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultivariateGaussianModel.__init__() takes from 3 to 4 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m agent: AgentQLearningGaussian \u001B[38;5;241m=\u001B[39m \u001B[43mAgentQLearningGaussian\u001B[49m\u001B[43m(\u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43ms2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43minit_weights_random\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/machine_learning/dayan3847/reinforcement_learning/cliff_walking/agent.py:217\u001B[0m, in \u001B[0;36mAgentQLearningGaussian.__init__\u001B[0;34m(self, env_, a, s2, init_weights_random)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms2 \u001B[38;5;241m=\u001B[39m s2  \u001B[38;5;66;03m# variance ^ 2\u001B[39;00m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_weights_random \u001B[38;5;241m=\u001B[39m init_weights_random\n\u001B[0;32m--> 217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_gaussian_models: \u001B[38;5;28mlist\u001B[39m[MultivariateGaussianModel] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_knowledge\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/machine_learning/dayan3847/reinforcement_learning/cliff_walking/agent.py:220\u001B[0m, in \u001B[0;36mAgentQLearningGaussian.reset_knowledge\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset_knowledge\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 220\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_gaussian_models \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    221\u001B[0m         MultivariateGaussianModel(\n\u001B[1;32m    222\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma,\n\u001B[1;32m    223\u001B[0m             (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m12\u001B[39m),\n\u001B[1;32m    224\u001B[0m             ((\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m4\u001B[39m), (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m12\u001B[39m)),\n\u001B[1;32m    225\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms2,\n\u001B[1;32m    226\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_weights_random,\n\u001B[1;32m    227\u001B[0m         ) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mactions_count)\n\u001B[1;32m    228\u001B[0m     ]\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_gaussian_models\n",
      "File \u001B[0;32m~/PycharmProjects/machine_learning/dayan3847/reinforcement_learning/cliff_walking/agent.py:221\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset_knowledge\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    220\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_gaussian_models \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m--> 221\u001B[0m         \u001B[43mMultivariateGaussianModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m            \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m            \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ms2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_weights_random\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mactions_count)\n\u001B[1;32m    228\u001B[0m     ]\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mq_gaussian_models\n",
      "\u001B[0;31mTypeError\u001B[0m: MultivariateGaussianModel.__init__() takes from 3 to 4 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "agent: AgentQLearningGaussian = AgentQLearningGaussian(environment,\n",
    "                                                       a=.1,\n",
    "                                                       s2=.1,\n",
    "                                                       init_weights_random=False,\n",
    "                                                       )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T20:14:20.841786009Z",
     "start_time": "2023-12-03T20:14:20.626461693Z"
    }
   },
   "id": "500b78fc0cbde117"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Trainner:\n",
    "    def __init__(\n",
    "            self,\n",
    "            a: AgentQLearning,\n",
    "            experiments_count: int,\n",
    "            episodes_count: int,\n",
    "    ):\n",
    "        self.agent: AgentQLearning = a\n",
    "        self.env: Environment = a.env\n",
    "        self.experiments_status: tuple[int, int] = 0, experiments_count  # Experiment 0 of 50\n",
    "        self.episodes_status: tuple[int, int] = 0, episodes_count  # Episode 0 of 500\n",
    "        # rewards promedio(de todos los experimentos) por episodio\n",
    "        self.rewards_sum: np.array = np.zeros(self.episodes_status[1])\n",
    "        # cantidad de veces que llego al final\n",
    "        self.success: np.array = np.zeros(self.episodes_status[1])\n",
    "\n",
    "    def get_title(self):\n",
    "        return 'Experiment: {}/{} Episode: {}/{}'.format(\n",
    "            self.experiments_status[0] + 1,\n",
    "            self.experiments_status[1],\n",
    "            self.episodes_status[0] + 1,\n",
    "            self.episodes_status[1]\n",
    "        )\n",
    "\n",
    "    def get_rewards_average(self) -> np.array:\n",
    "        return self.rewards_sum / (self.experiments_status[0] + 1)\n",
    "\n",
    "    def train(self):\n",
    "        for i_exp in range(self.experiments_status[1]):\n",
    "            self.experiments_status = i_exp, self.experiments_status[1]\n",
    "            self.agent.reset_knowledge()\n",
    "            for i_epi in range(self.episodes_status[1]):\n",
    "                self.episodes_status = i_epi, self.episodes_status[1]\n",
    "                print(self.get_title())\n",
    "                episode_end: bool = False\n",
    "                while not episode_end:\n",
    "                    reward, episode_end = self.agent.run_step()\n",
    "                    self.rewards_sum[i_epi] += reward\n",
    "                    if episode_end and reward > 0:\n",
    "                        self.success[i_epi] += 1\n",
    "\n",
    "\n",
    "trainner = Trainner(agent,\n",
    "                    experiments_count=1,\n",
    "                    episodes_count=1000,\n",
    "                    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.839758812Z"
    }
   },
   "id": "aeda226441e09f9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Train\n",
    "trainner.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.839891353Z"
    }
   },
   "id": "4a680a13d6fe85ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Save Knowledge\n",
    "#agent.save_knowledge()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840078359Z"
    }
   },
   "id": "b45417b95a40558d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Plot Rewards\n",
    "def plot_rewards_average():\n",
    "    plt.plot(trainner.get_rewards_average(), label='Reward Average')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward Average')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_rewards_average()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840608722Z"
    }
   },
   "id": "a7c1e3b556273ffe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Plot Success\n",
    "def plot_success():\n",
    "    plt.plot(trainner.success, label='Success')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Success')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_success()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840712753Z"
    }
   },
   "id": "a4dce7778103de6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Plot Best Action\n",
    "def plot_best_action():\n",
    "    best_actions = agent.get_best_actions_for_all_states()\n",
    "    plt.matshow(best_actions, label='Best Action')\n",
    "    m, n = best_actions.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            _cell = best_actions[i, j]\n",
    "            cell = '↑' if _cell == 0 \\\n",
    "                else '↓' if _cell == 1 \\\n",
    "                else '←' if _cell == 2 \\\n",
    "                else '→' if _cell == 3 \\\n",
    "                else 'X'\n",
    "            plt.text(j, i, cell, ha='center', va='center', color='red', fontsize=50)\n",
    "\n",
    "    plt.xlabel('State_0')\n",
    "    plt.ylabel('State_1')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_best_action()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840795486Z"
    }
   },
   "id": "cd88abc56fd6afe9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Plot Board Incidence\n",
    "def plot_board_incidence():\n",
    "    plt.matshow(trainner.env.board_incidence, label='Board Incidence')\n",
    "    m, n = trainner.env.board_incidence.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            plt.text(j, i, trainner.env.board_incidence[i, j], ha='center', va='center', fontsize=11)\n",
    "\n",
    "    plt.xlabel('State_0')\n",
    "    plt.ylabel('State_1')\n",
    "    plt.colorbar()\n",
    "    plt.set_cmap('plasma')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_board_incidence()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840857317Z"
    }
   },
   "id": "c809ebe573f08d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Plot the Q-Models\n",
    "def plot_q_table_histograms():\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    fig.suptitle('Q-Models')\n",
    "\n",
    "    # UP\n",
    "    ax = fig.add_subplot(221, projection='3d')\n",
    "    ax.set_title('Action: UP')\n",
    "    ax.set_xlabel('State_0')\n",
    "    ax.set_ylabel('State_1')\n",
    "    ax.set_zlabel('Q-Value')\n",
    "    _model = agent.q_gaussian_models[0]\n",
    "    _x, _y = _model.data_to_plot_matplotlib()\n",
    "    ax.plot_trisurf(_x[0], _x[1], _y, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # DOWN\n",
    "    ax = fig.add_subplot(222, projection='3d')\n",
    "    ax.set_title('Action: DOWN')\n",
    "    ax.set_xlabel('State_0')\n",
    "    ax.set_ylabel('State_1')\n",
    "    ax.set_zlabel('Q-Value')\n",
    "    _model = agent.q_gaussian_models[1]\n",
    "    _x, _y = _model.data_to_plot_matplotlib()\n",
    "    ax.plot_trisurf(_x[0], _x[1], _y, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # LEFT\n",
    "    ax = fig.add_subplot(223, projection='3d')\n",
    "    ax.set_title('Action: LEFT')\n",
    "    ax.set_xlabel('State_0')\n",
    "    ax.set_ylabel('State_1')\n",
    "    ax.set_zlabel('Q-Value')\n",
    "    _model = agent.q_gaussian_models[2]\n",
    "    _x, _y = _model.data_to_plot_matplotlib()\n",
    "    ax.plot_trisurf(_x[0], _x[1], _y, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # RIGHT\n",
    "    ax = fig.add_subplot(224, projection='3d')\n",
    "    ax.set_title('Action: RIGHT')\n",
    "    ax.set_xlabel('State_0')\n",
    "    ax.set_ylabel('State_1')\n",
    "    ax.set_zlabel('Q-Value')\n",
    "    _model = agent.q_gaussian_models[3]\n",
    "    _x, _y = _model.data_to_plot_matplotlib()\n",
    "    ax.plot_trisurf(_x[0], _x[1], _y, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # show\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_q_table_histograms()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840921548Z"
    }
   },
   "id": "da143d5e52adc2f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-03T20:14:20.840987666Z"
    }
   },
   "id": "3e624d7ad4e4b00a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
